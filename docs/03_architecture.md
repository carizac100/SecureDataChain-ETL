# 03 â€“ System Architecture and Data Flow

## 1. Overview
This document describes the technical architecture of the **SecureDataChain ETL Project**, illustrating how data moves from raw sources through the ETL pipeline and is finally secured using a blockchain-based integrity layer.

---

## 2. System Components
| Component | Description | Technology |
|------------|-------------|-------------|
| **Raw Data Source** | Input logs, events, or datasets (synthetic or anonymized). | CSV, JSON, APIs |
| **ETL Pipeline** | Extracts, cleans, transforms, and loads data. | Python (pandas, hashlib) |
| **Hash Generator** | Creates a SHA-256 hash of the processed dataset. | Python hashlib |
| **Blockchain Layer** | Records dataset hashes for immutability and traceability. | Custom Python module |
| **Verification Module** | Validates dataset integrity by comparing stored and computed hashes. | Python CLI or script |

---

## 3. Data Flow Diagram

```mermaid
flowchart TD
    A[ğŸ—‚ï¸ Data Source(s)] --> B[âš™ï¸ ETL Pipeline<br/>(Extract / Transform / Load)]
    B --> C[ğŸ”‘ Hash Generator<br/>(SHA-256 Digest)]
    C --> D[â›“ï¸ Blockchain Layer<br/>(Record + Verify)]
    D --> E[ğŸ” Data Integrity<br/>Verification]





## 4. Architecture Layers

1. **Data Layer** â†’ contains raw and processed datasets (`/data/raw` and `/data/processed`).  
2. **Processing Layer** â†’ handles ETL and data transformation logic (`src/etl_pipeline.py`).  
3. **Integrity Layer** â†’ generates dataset hashes and records them in blockchain (`src/blockchain.py`).  
4. **Validation Layer** â†’ verifies integrity and alerts if data has been altered.  

---

## 5. User runs the ETL pipeline on raw data:

 "python src/etl_pipeline.py"


